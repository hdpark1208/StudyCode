{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NLP_Keras(8-6).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hdpark1208/StudyCode/blob/main/NLP/NLP_Keras(8_6).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G05L1r8eoK-h"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVHSOEphoK-j",
        "outputId": "ddbb6294-efb9-4ebb-9084-02363a644741"
      },
      "source": [
        "# Tokenizer()\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()\n",
        "fit_text = \"The earth is an awesome place live\"\n",
        "t.fit_on_texts([fit_text])\n",
        "\n",
        "test_text = \"The earth is an great place live\"\n",
        "sequences = t.texts_to_sequences([test_text])[0]\n",
        "\n",
        "print('sequences : ',sequences) # great는 단어 집합(vocabulary)에 없으므로 출력 X\n",
        "print(\"word_index : \",t.word_index) # 단어 집합 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences :  [1, 2, 3, 4, 6, 7]\n",
            "word_index :  {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'live': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4yZnu5zoK-l",
        "outputId": "6f55c4e7-6d93-41f0-bbce-54ef4124b270"
      },
      "source": [
        "# Padding : 샘플의 길이를 동일하게 맞춰줌\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "pad_sequences([[1,2,3],[3,4,5,6,],[7,8]],maxlen=3,padding='pre')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6],\n",
              "       [0, 7, 8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNBDkA3ioK-l"
      },
      "source": [
        "### Embedding\n",
        "정수 인코딩이 된 단어들을 입력받아 밀집 벡터로 만든다  \n",
        " 문장 토큰화와 단어 토큰화  \n",
        "text=[['Hope', 'to', 'see', 'you', 'soon'],['Nice', 'to', 'see', 'you', 'again']]  \n",
        "\n",
        " 각 단어에 대한 정수 인코딩  \n",
        "text=[[0, 1, 2, 3, 4],[5, 1, 2, 3, 6]]  \n",
        "\n",
        " 위 데이터가 아래의 임베딩 층의 입력이 된다.  \n",
        "Embedding(7, 2, input_length=5)  \n",
        " 7은 단어의 개수. 즉, 단어 집합(vocabulary)의 크기이다.  \n",
        " 2는 임베딩한 후의 벡터의 크기이다.  \n",
        " 5는 각 입력 시퀀스의 길이. 즉, input_length이다.  \n",
        "\n",
        " 각 정수는 아래의 테이블의 인덱스로 사용되며 Embeddig()은 각 단어에 대해 임베딩 벡터를 리턴한다.  \n",
        "+------------+------------+  \n",
        "|   index    | embedding  |  \n",
        "+------------+------------+  \n",
        "|     0      | [1.2, 3.1] |  \n",
        "|     1      | [0.1, 4.2] |  \n",
        "|     2      | [1.0, 3.1] |  \n",
        "|     3      | [0.3, 2.1] |  \n",
        "|     4      | [2.2, 1.4] |  \n",
        "|     5      | [0.7, 1.7] |  \n",
        "|     6      | [4.1, 2.0] |  \n",
        "+------------+------------+  \n",
        " 위의 표는 임베딩 벡터가 된 결과를 예로서 정리한 것이고 Embedding()의 출력인 3D 텐서를 보여주는 것이 아님.  \n",
        "* 첫번째 인자 = 단어 집합의 크기. 즉, 총 단어의 개수  \n",
        "* 두번째 인자 = 임베딩 벡터의 출력 차원. 결과로서 나오는 임베딩 벡터의 크기  \n",
        "* input_length = 입력 시퀀스의 길이  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSr91x4XoK-m"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2exuaMroK-m"
      },
      "source": [
        "Sequential() : 인공 신경망 챕터에서 입력층, 은닉층, 출력층에 대해서 배웠습니다. 케라스에서는 이러한 층을 구성하기 위해 Sequential()을 사용합니다. Sequential()을 model로 선언한 뒤에 model.add()라는 코드를 통해 층을 단계적으로 추가합니다. 아래는 model.add()로 층을 추가하는 예제 코드를 보여줍니다. 실제로는 괄호 사이에 있는 온점 대신에 실제 층의 이름을 기재해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqotLqW4oK-m"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=3, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wC_hgDwoK-n"
      },
      "source": [
        "위의 코드에서 Dense()는 한번 사용되었지만 더 많은 층을 추가할 수 있습니다. Dense()의 대표적인 인자를 보겠습니다.\n",
        "\n",
        "첫번째 인자 = 출력 뉴런의 수.  \n",
        "input_dim = 입력 뉴런의 수. (입력의 차원)  \n",
        "activation = 활성화 함수.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGyGsVBkoK-n"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM0Xvbu2oK-n"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid')) # 출력층"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5t2X3zjoK-o"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc8QLw72oK-o",
        "outputId": "503ad671-acb3-4fd6-f176-95c3c8a034d7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 49\n",
            "Trainable params: 49\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2cg9uWUoK-o"
      },
      "source": [
        "## Compile & Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9jzK-QPoK-p"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__CRTOmYoK-p"
      },
      "source": [
        "optimizer : 훈련 과정을 설정하는 옵티마이저를 설정합니다. 'adam'이나 'sgd'와 같이 문자열로 지정할 수도 있습니다.  \n",
        "loss : 훈련 과정에서 사용할 손실 함수(loss function)를 설정합니다.  \n",
        "metrics : 훈련을 모니터링하기 위한 지표를 선택합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srWo6rTLoK-p"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpu0pixGoK-p"
      },
      "source": [
        "첫번째 인자 = 훈련 데이터에 해당됩니다.  \n",
        "두번째 인자 = 지도 학습에서 레이블 데이터에 해당됩니다.  \n",
        "epochs = 에포크. 에포크 1은 전체 데이터를 한 차례 훑고 지나갔음을 의미함. 정수값 기재 필요. 총 훈련 횟수를 정의합니다.  \n",
        "batch_size = 배치 크기. 기본값은 32. 미니 배치 경사 하강법을 사용하고 싶지 않을 경우에는 batch_size=None을 기재합니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2eX7mdKoK-p"
      },
      "source": [
        "## Evaluation & Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wusN7j3oK-q"
      },
      "source": [
        "* evaluate() : 테스트 데이터를 통해 학습한 모델에 대한 정확도를 평가합니다  \n",
        "첫번째 인자 = 테스트 데이터에 해당됩니다.  \n",
        "두번째 인자 = 지도 학습에서 레이블 테스트 데이터에 해당됩니다.  \n",
        "batch_size = 배치 크기.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21qJ5ZVioK-q"
      },
      "source": [
        "model.evaluate(X_test, y_test, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6GRbpghoK-q"
      },
      "source": [
        "* predict() : 임의의 입력에 대한 모델의 출력값을 확인합니다  \n",
        "첫번째 인자 = 예측하고자 하는 데이터   \n",
        "batch_size = 배치 크기  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDHdNXCgoK-q"
      },
      "source": [
        "model.predict(X_input,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7AEWwEWoK-q"
      },
      "source": [
        "## Save & Load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24tpgj1_oK-q"
      },
      "source": [
        "* save() : 인공 신경망 모델을 hdf5 파일에 저장합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSu89jOroK-r"
      },
      "source": [
        "model.save(\"model_name.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHVnZ57oK-r"
      },
      "source": [
        "* load_model() : 저장해둔 모델을 불러옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTsn1t0YoK-r"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('model_name.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmtxaw72oK-r"
      },
      "source": [
        "8. 07)~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFxN7Q-VoK-r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}