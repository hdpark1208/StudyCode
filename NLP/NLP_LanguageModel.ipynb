{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NLP_LanguageModel.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hdpark1208/StudyCode/blob/main/NLP/NLP_LanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXT1jLEuf6N1"
      },
      "source": [
        "## 통계적 언어모델(Statistical Language Model, SLM)\n",
        "> 조건부 확률에 의한 카운트 기반의 접근방식\n",
        "* 카운터 기반 접근의 한계 - 희소 문제(Sparsity Problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az4czTHxf6N2"
      },
      "source": [
        "### N-gram Language Model\n",
        "> n-gram : n개의 연속적인 단어 뭉치\n",
        "> 앞의 n 개의 단어를 통해 유추한다. 하지만 n이 작을 경우 문맥이 고려되지 않을 수 있다는 문제가 있다  \n",
        "> 그렇다고 n을 크게 선택할 경우 희소 문제는 커지므로 trade-off 문제가 된다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LuxfBszf6N3"
      },
      "source": [
        "## 언어 모델의 평가 방법(Evaluation Metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEFdXh43f6N3"
      },
      "source": [
        "* Perplexity(PPL) : 언어모델을 평가하기 위한 내부 평가 지표 ~ 헷갈리는 정도 \n",
        "* PPL은 선택할 수 있는 가능한 경우의 수를 의미하는 분기계수(branching factor)이다\n",
        "* PPL이 낮다는 것은 테스트 데이터 상에서 높은 정확도를 보인다는 의미. 반드시 문맥적으로 좋다는 걸 의미하진 않는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW-nuRWYf6N3"
      },
      "source": [
        "## 단어의 표현 방법\n",
        "1. Local Representation (Discrete)\n",
        "2. Distributed Representation (Continuous)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llYm-2a8f6N4"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "출처 : https://wikidocs.net/31767"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8GjLkJlf6N4"
      },
      "source": [
        "## Bag of Words(BOW)\n",
        "> 단어의 빈도에만 집중하는 텍스트 데이터의 수치화 표현 방법\n",
        "1. 각 단어에 고유한 정수 인덱스를 부여한다\n",
        "2. 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만든다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGNkvCGof6N4"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "import re\n",
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vscHsSzvf6N5"
      },
      "source": [
        "* insert(a, b)는 리스트의 a번째 위치에 b를 삽입하는 함수이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqaFyKMJf6N6",
        "outputId": "63b4b803-c260-4747-e692-027372027de8"
      },
      "source": [
        "test = [1,2,3,4,5]\n",
        "test.insert(3,30)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 30, 4, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBnhFlJPf6N6",
        "outputId": "3b130fef-aac8-4a7b-f9b5-e420435e3ad7"
      },
      "source": [
        "test = {0:0,1:10,2:20,3:30}\n",
        "test.get(3) # value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5szn-snMf6N6",
        "outputId": "e90bae67-f02a-46e3-a6d9-e78fac057308"
      },
      "source": [
        "sentence = \"정.부가 발.표하는 물가상.승률.과. .소비자가 느끼는 물가상승률은 다르다.\"\n",
        "token = re.sub(\"(\\.)\",\"\",sentence) # 정규표현식을 통해 온점을 제거하는 정제 작업\n",
        "print(token,\"\\n\")\n",
        "token=okt.morphs(token) # OKT 형태소 분석기를 통해 토큰화 작업을 수행\n",
        "print(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다 \n",
            "\n",
            "['정부', '가', '발표', '하는', '물가상승률', '과', '소비자', '가', '느끼는', '물가상승률', '은', '다르다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeqJBmErf6N7",
        "outputId": "170f1baa-3501-45a8-91c3-d76f36fdac02"
      },
      "source": [
        "word2index={}\n",
        "bow=[]\n",
        "for voca in token:\n",
        "    if voca not in word2index.keys():\n",
        "        word2index[voca]=len(word2index) \n",
        "        # token을 읽으면서, word2index에 없는 단어를 word2index에 추가\n",
        "        # 그러면 word2index 의 길이가 1 늘어나므로 인덱스를 겹치지않고 계속 부여할 수 있다\n",
        "        bow.insert(len(word2index)-1,1)\n",
        "        #리스트에도 자리마다 1을 넣어준다\n",
        "    else:\n",
        "        index = word2index.get(voca)\n",
        "        bow[index]=bow[index]+1\n",
        "        \n",
        "print(word2index) # 각 token의 인덱스\n",
        "print(bow) # 인덱스가 가르키는 token의 빈도"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
            "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW7oj982f6N7",
        "outputId": "e1eca01c-104f-4abf-cf38-9ab9b7cee5d3"
      },
      "source": [
        "sentence1 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'\n",
        "token = re.sub(\"(\\.)\",\"\",sentence1)\n",
        "token = okt.morphs(token)\n",
        "\n",
        "for voca in token: # 문장 추가\n",
        "    if voca not in word2index.keys():\n",
        "        word2index[voca]=len(word2index) \n",
        "        bow.insert(len(word2index)-1,1)\n",
        "    else:\n",
        "        index = word2index.get(voca)\n",
        "        bow[index]=bow[index]+1\n",
        "        \n",
        "print(word2index) # 각 token의 인덱스\n",
        "print(bow) # 인덱스가 가르키는 token의 빈도"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9, '는': 10, '주로': 11, '소비': 12, '상품': 13, '을': 14, '기준': 15, '으로': 16, '느낀다': 17}\n",
            "[1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV5aWVJIf6N7"
      },
      "source": [
        "* 라이브러리를 이용하여 빠르게"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2NWCI0Af6N8",
        "outputId": "435426c2-6230-488d-93e6-0c914fead813"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = ['you know i want your love. because i love you.']\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray())\n",
        "print(vector.vocabulary_)\n",
        "# CountVectorizer는 길이가 2 이상인 문자만 토큰으로 인식한다(Cleaning)\n",
        "# i 제거"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 2 1 2 1]]\n",
            "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ2ZKSaSf6N8"
      },
      "source": [
        "* 사용자지정 불용어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K78XjUptf6N8",
        "outputId": "6dfd8831-bcb4-4f04-ecd8-076ff7e8d7f9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text =[\"Family is not an important thing. It's everything\"]\n",
        "vect = CountVectorizer(stop_words=[\"the\",\"a\",\"an\",\"is\",\"not\"])\n",
        "print(vect.fit_transform(text).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjrFToH_f6N8"
      },
      "source": [
        "* CountVectorizer 불용어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XNrBzb2f6N8",
        "outputId": "8bb5e537-bfae-493c-d3fc-69316e9eb2e1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything. every any some\"]\n",
        "vect = CountVectorizer(stop_words=\"english\")\n",
        "print(vect.fit_transform(text).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1]]\n",
            "{'family': 0, 'important': 1, 'thing': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m4W5nBYf6N9"
      },
      "source": [
        "* NLTK 불용어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzV9vGixf6N9",
        "outputId": "56d2935c-bbef-49d8-ce98-6acb977d9f34"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything. every any some\"]\n",
        "sw = stopwords.words(\"english\")\n",
        "vect = CountVectorizer(stop_words =sw)\n",
        "print(vect.fit_transform(text).toarray()) \n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1 1 1]]\n",
            "{'family': 2, 'important': 3, 'thing': 4, 'everything': 1, 'every': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P4gBo3vf6N9"
      },
      "source": [
        "## Document-Term Matrix, DTM\n",
        "> 서로 다른 문서들의 Bow들을 결합한 표현 방법 ( 각 Bow를 행으로 하는 행렬)\n",
        "* 문서 간 비교가 가능하게 수치화시킨다는 의의가 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MIAke2bf6N9"
      },
      "source": [
        "## TF-IDF(Term Frequency-Inverse Document Frequency)\n",
        "> 단어의 빈도와 역 문서 빈도(문서의 빈도에 특정 식을 취하는 식)를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법  \n",
        "1. DTM을 만든다\n",
        "2. TF-IDF 가중치를 부여한다\n",
        "* 특정 단어의 빈도가 높으면 중요하게 보지만 그 단어가 모든 문서에 쓰이는 단어라면 덜 중요하게 보는 것이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbIO0JbCf6N9"
      },
      "source": [
        "# 직접 구현\n",
        "import pandas as pd\n",
        "from math import log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yutyJ_Xpf6N9",
        "outputId": "1bf8e1e1-e50d-4c86-cff4-ae9ac1e31697"
      },
      "source": [
        "docs = [\n",
        "    '먹고 싶은 바나나',\n",
        "    '먹고 싶은 사과',\n",
        "    '길고 노란 바나나 바나나',\n",
        "    '저는 과일이 좋아요'\n",
        "]\n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "\n",
        "vocab.sort()\n",
        "\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWnamcpuf6N-"
      },
      "source": [
        "N = len(docs) # 총 문서의 수\n",
        "\n",
        "def tf(t,d): # 특정문서 d에서 단어 t가 나온 횟수\n",
        "    return d.count(t)\n",
        "\n",
        "def idf(t): # \n",
        "    df = 0\n",
        "    for doc in docs:\n",
        "        df += t in doc\n",
        "    return log(N/(df+1))\n",
        "\n",
        "def tfidf(t,d):\n",
        "    return tf(t,d)*idf(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RWAc8NBf6N-",
        "outputId": "d74eca38-a124-41e6-bbfc-6a1a3a88aff2"
      },
      "source": [
        "tf('나','나 나나 나비 너 너 나무')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsAyVwQLf6N-",
        "outputId": "237b5221-d543-4919-b17c-ddd80ae9bcae"
      },
      "source": [
        "test = 0\n",
        "\n",
        "test += '나' in '나 나무 나 무 나무나무' # 있으면 1 없으면 0\n",
        "test += '나무' in '나 나무 나 무 나무나무' # 있으면 1 없으면 0\n",
        "test += '무나' in '나 나무 나 무 나무나무' # 있으면 1 없으면 0\n",
        "test += '물' in '나 나무 나 무 나무나무' # 있으면 1 없으면 0\n",
        "\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRrLg5fAf6N-",
        "outputId": "c57e8927-84ca-4ba0-c68f-88601c7a451d"
      },
      "source": [
        "result = []\n",
        "for i in range(N):\n",
        "    result.append([])\n",
        "    d = docs[i]\n",
        "    for j in range(len(vocab)):\n",
        "        t = vocab[j]\n",
        "        result[-1].append(tf(t,d))\n",
        "tf_ = pd.DataFrame(result,columns = vocab)\n",
        "tf_\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>과일이</th>\n",
              "      <th>길고</th>\n",
              "      <th>노란</th>\n",
              "      <th>먹고</th>\n",
              "      <th>바나나</th>\n",
              "      <th>사과</th>\n",
              "      <th>싶은</th>\n",
              "      <th>저는</th>\n",
              "      <th>좋아요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
              "0    0   0   0   1    1   0   1   0    0\n",
              "1    0   0   0   1    0   1   1   0    0\n",
              "2    0   1   1   0    2   0   0   0    0\n",
              "3    1   0   0   0    0   0   0   1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqCgYtQNf6N-",
        "outputId": "d3a825a0-3843-453a-ea3f-cf23b2ebda88"
      },
      "source": [
        "result = []\n",
        "for j in range(len(vocab)):\n",
        "    t= vocab[j]\n",
        "    result.append(idf(t))\n",
        "    \n",
        "idf_ = pd.DataFrame(result,index = vocab,columns = ['IDF'])\n",
        "idf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>과일이</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>길고</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>노란</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>먹고</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>바나나</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>사과</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>싶은</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>저는</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>좋아요</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          IDF\n",
              "과일이  0.693147\n",
              "길고   0.693147\n",
              "노란   0.693147\n",
              "먹고   0.287682\n",
              "바나나  0.287682\n",
              "사과   0.693147\n",
              "싶은   0.287682\n",
              "저는   0.693147\n",
              "좋아요  0.693147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zukQZg6Ff6N-",
        "outputId": "b335c8a4-ed35-4827-d45d-13676a9e66ef"
      },
      "source": [
        "result = []\n",
        "for i in range(N):\n",
        "    result.append([])\n",
        "    d = docs[i]\n",
        "    for j in range(len(vocab)):\n",
        "        t = vocab[j]\n",
        "\n",
        "        result[-1].append(tfidf(t,d))\n",
        "\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
        "tfidf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>과일이</th>\n",
              "      <th>길고</th>\n",
              "      <th>노란</th>\n",
              "      <th>먹고</th>\n",
              "      <th>바나나</th>\n",
              "      <th>사과</th>\n",
              "      <th>싶은</th>\n",
              "      <th>저는</th>\n",
              "      <th>좋아요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.575364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        과일이        길고        노란        먹고       바나나        사과        싶은  \\\n",
              "0  0.000000  0.000000  0.000000  0.287682  0.287682  0.000000  0.287682   \n",
              "1  0.000000  0.000000  0.000000  0.287682  0.000000  0.693147  0.287682   \n",
              "2  0.000000  0.693147  0.693147  0.000000  0.575364  0.000000  0.000000   \n",
              "3  0.693147  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "         저는       좋아요  \n",
              "0  0.000000  0.000000  \n",
              "1  0.000000  0.000000  \n",
              "2  0.000000  0.000000  \n",
              "3  0.693147  0.693147  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddiRjqonf6N_"
      },
      "source": [
        "* 사이킷런을 이용한 TF-IDE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYWeckCQf6N_",
        "outputId": "d70febb9-e490-4e5c-9066-f7ade70c2af2"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'you know I want your love',\n",
        "    'I like you',\n",
        "    'what should I do ',    \n",
        "]\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 1 0 1 0 1 1]\n",
            " [0 0 1 0 0 0 0 1 0]\n",
            " [1 0 0 0 1 0 1 0 0]]\n",
            "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijHYMy3qf6N_",
        "outputId": "101bb598-43e2-4b8a-fce6-f68076143f61"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "    'you know I want your love',\n",
        "    'I like you',\n",
        "    'what should I do ',    \n",
        "]\n",
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "print(tfidfv.transform(corpus).toarray())\n",
        "print(tfidfv.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
            "  0.         0.35543247 0.46735098]\n",
            " [0.         0.         0.79596054 0.         0.         0.\n",
            "  0.         0.60534851 0.        ]\n",
            " [0.57735027 0.         0.         0.         0.57735027 0.\n",
            "  0.57735027 0.         0.        ]]\n",
            "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6fkAfpKf6N_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}